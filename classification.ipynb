{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Success Level Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 6)\n",
    "plt.style.use(\"dark_background\")\n",
    "ENDDEL = \"\\n\\t\" + \"---\" * 15 + \"\\n\"\n",
    "pd.set_option(\"display.float_format\", \"{:,.0f}\".format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train):\n",
    "    directory = \"Training_data/\" if train == True else \"Testing_data/\"\n",
    "    directors = pd.read_csv(directory + \"Classification_data/movie-director.csv\", header=0, names=[\"Movie_Title\", \"Director\"])\n",
    "    actors = pd.read_csv(\n",
    "        directory + \"Classification_data/movie-voice-actors.csv\", header=0, names=[\"Character\", \"Actor\", \"Movie_Title\"]\n",
    "    )\n",
    "    success_lvl = pd.read_csv(\n",
    "        directory + \"Classification_data/movie-success-level.csv\",\n",
    "        header=0,\n",
    "        names=[\"Movie_Title\", \"Release_Date\", \"Genre\", \"MPAA_Rating\", \"Success_Level\"],\n",
    "    )\n",
    "\n",
    "    success_lvl.Release_Date = pd.to_datetime(success_lvl.Release_Date, format=\"%d-%b-%y\")\n",
    "    # Fix incorrect year parsing\n",
    "    success_lvl.Release_Date = success_lvl.Release_Date.apply(\n",
    "        lambda x: x.replace(year=x.year - 100 if x.year > dt.today().year else x.year)\n",
    "    )\n",
    "\n",
    "    return pd.merge(directors, pd.merge(actors, success_lvl, on=\"Movie_Title\", how=\"outer\"), on=\"Movie_Title\", how=\"outer\")\n",
    "\n",
    "\n",
    "original_data = load_data(True)\n",
    "original_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.drop([\"Release_Date\"], axis=1).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.Release_Date.describe(datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.Success_Level.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_fill_na(x):\n",
    "    a = set(original_data[\"Movie_Title\"][original_data[x].notna()])\n",
    "    b = set(original_data[\"Movie_Title\"][original_data[x].isna()])\n",
    "    c = a - b\n",
    "    # if they show up in both sets then they can be filled\n",
    "    return (len(a) - len(b)) == len(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there movies with the same title and missing X ?\n",
    "print(can_fill_na(\"Success_Level\"))\n",
    "print(can_fill_na(\"Director\"))\n",
    "print(can_fill_na(\"Genre\"))\n",
    "print(can_fill_na(\"MPAA_Rating\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No, then drop those records\n",
    "original_data.dropna(subset=[\"Success_Level\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise features\n",
    "original_data.drop([\"Character\", \"Actor\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.set_index(\"Movie_Title\").groupby(\"Movie_Title\").sample(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.set_index(\"Movie_Title\").groupby(\"Movie_Title\").sample(frac=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.Director.fillna(\"Other\", inplace=True)\n",
    "original_data.Genre.fillna(\"Other\", inplace=True)\n",
    "original_data.MPAA_Rating.fillna(\"Not Rated\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data):\n",
    "    data.Success_Level = data.Success_Level.map({\"S\": 0, \"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4})\n",
    "\n",
    "    data[\"Release_Day\"] = data.Release_Date.dt.day\n",
    "    data[\"Release_Month\"] = data.Release_Date.dt.month\n",
    "    data[\"Release_Year\"] = data.Release_Date.dt.year\n",
    "\n",
    "    data[\"Recent_Movie\"] = dt.today().year - data[\"Release_Year\"]\n",
    "\n",
    "    data.drop([\"Release_Date\"], axis=1, inplace=True)\n",
    "\n",
    "    data.Recent_Movie = data.Recent_Movie < 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_features(original_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"Success_Level\", \"Director\", \"Genre\", \"MPAA_Rating\", \"Recent_Movie\"]\n",
    "numerical_features = [\"Release_Day\", \"Release_Month\", \"Release_Year\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "for i, f in enumerate(categorical_features[:-1]):\n",
    "    sb.histplot(original_data[f], ax=ax[i // 2, i % 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "for i, f in enumerate(numerical_features):\n",
    "    sb.histplot(original_data[f], ax=ax[i // 2, i % 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using single features to predict success level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=original_data.Release_Day, y=np.zeros(original_data.shape[0]), hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=original_data.Release_Month, y=np.zeros(original_data.shape[0]), hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=original_data.Release_Year, y=np.zeros(original_data.shape[0]), hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=original_data.Genre, y=np.zeros(original_data.shape[0]), hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=original_data.MPAA_Rating, y=np.zeros(original_data.shape[0]), hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.scatterplot(x=original_data.Director, y=np.zeros(original_data.shape[0]), hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion: No obvious way to separate features on 1D plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pairs of features to predict success level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(x=original_data.Release_Year, y=original_data.MPAA_Rating, hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(x=original_data.Director, y=original_data.MPAA_Rating, hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(x=original_data.Genre, y=original_data.MPAA_Rating, hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.stripplot(x=original_data.Genre, y=original_data.Director, hue=original_data.Success_Level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "x_train = original_data.drop([\"Movie_Title\"], axis=1)\n",
    "y_train = original_data[\"Success_Level\"]\n",
    "\n",
    "x_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"first\"), [\"Genre\", \"Director\", \"MPAA_Rating\", \"Recent_Movie\"]),\n",
    "    (MinMaxScaler(), [\"Release_Day\", \"Release_Month\", \"Release_Year\"]),\n",
    "    n_jobs=-1,\n",
    "    sparse_threshold=0,\n",
    "    verbose_feature_names_out=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_x_train = column_transformer.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_x_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_cv = cross_val_score(nb_model, prep_x_train, y_train, cv=10)\n",
    "print(\"Naive Bayes CV\", nb_cv, nb_cv.mean(), sep=\"\\n\", end=ENDDEL)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_cv = cross_val_score(lr_model, prep_x_train, y_train, cv=10)\n",
    "print(\"Logistic Regression CV\", lr_cv, lr_cv.mean(), sep=\"\\n\", end=ENDDEL)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=7)\n",
    "dt_cv = cross_val_score(dt_model, prep_x_train, y_train, cv=10)\n",
    "print(\"Decision Tree CV\", dt_cv, dt_cv.mean(), sep=\"\\n\", end=ENDDEL)\n",
    "\n",
    "# Support Vector Machine\n",
    "svc_model = SVC(probability=True)\n",
    "svc_cv = cross_val_score(svc_model, prep_x_train, y_train, cv=10)\n",
    "print(\"Support Vector Machine CV\", svc_cv, svc_cv.mean(), sep=\"\\n\", end=ENDDEL)\n",
    "\n",
    "# K Nearest Neighbour\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_cv = cross_val_score(knn_model, prep_x_train, y_train, cv=10)\n",
    "print(\"K Nearest Neighbour CV\", knn_cv, knn_cv.mean(), sep=\"\\n\", end=ENDDEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "xgb_model = XGBClassifier(random_state=7)\n",
    "xgb_cv = cross_val_score(xgb_model, prep_x_train, y_train, cv=10)\n",
    "print(\"Gradient Boost CV\", xgb_cv, xgb_cv.mean(), sep=\"\\n\", end=ENDDEL)\n",
    "\n",
    "# Random forest\n",
    "rf_model = RandomForestClassifier(random_state=7)\n",
    "rf_cv = cross_val_score(rf_model, prep_x_train, y_train, cv=10)\n",
    "print(\"Random forest CV\", rf_cv, rf_cv.mean(), sep=\"\\n\", end=ENDDEL)\n",
    "\n",
    "# Voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"nb_model\", nb_model),\n",
    "        (\"lr_model\", lr_model),\n",
    "        (\"dt_model\", dt_model),\n",
    "        (\"svc_model\", svc_model),\n",
    "        (\"knn_model\", knn_model),\n",
    "        (\"rf_model\", rf_model),\n",
    "        (\"xgb_model\", xgb_model),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "vc_cv = cross_val_score(voting_clf, prep_x_train, y_train, cv=10)\n",
    "print(\"Voting Classifier CV\", vc_cv, vc_cv.mean(), sep=\"\\n\", end=ENDDEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logitic regression\n",
    "lr_gs = GridSearchCV(\n",
    "    lr_model,\n",
    "    param_grid={\"max_iter\": [2000, 4000, 6000], \"penalty\": [\"l1\", \"l2\"], \"C\": np.logspace(-4, 4, 20), \"solver\": [\"liblinear\"]},\n",
    "    cv=10,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ").fit(prep_x_train, y_train)\n",
    "print(\"best score:\", lr_gs.best_score_)\n",
    "print(\"best parameters:\", lr_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_gs = GridSearchCV(\n",
    "    knn_model,\n",
    "    param_grid={\n",
    "        \"n_neighbors\": [3, 5, 7, 9],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"],\n",
    "        \"p\": [1, 2],\n",
    "    },\n",
    "    cv=10,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ").fit(prep_x_train, y_train)\n",
    "print(\"best score:\", knn_gs.best_score_)\n",
    "print(\"best parameters:\", knn_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "svc_gs = GridSearchCV(\n",
    "    svc_model,\n",
    "    param_grid=[\n",
    "        {\"kernel\": [\"rbf\"], \"gamma\": [0.1, 0.5, 1, 5, 10], \"C\": [0.1, 1, 10, 100]},\n",
    "        {\"kernel\": [\"linear\"], \"C\": [0.1, 1, 10, 100]},\n",
    "        {\"kernel\": [\"poly\"], \"degree\": [2, 3], \"C\": [0.1, 1, 10, 100]},\n",
    "    ],\n",
    "    cv=10,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ").fit(prep_x_train, y_train)\n",
    "print(\"best score:\", svc_gs.best_score_)\n",
    "print(\"best parameters:\", svc_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rf_gs = GridSearchCV(\n",
    "    rf_model,\n",
    "    param_grid={\n",
    "        \"n_estimators\": [400, 500, 550],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"bootstrap\": [True],\n",
    "        \"max_depth\": [15, 20],\n",
    "        \"max_features\": [\"sqrt\", 10],\n",
    "        \"min_samples_leaf\": [2, 3],\n",
    "        \"min_samples_split\": [2, 3],\n",
    "    },\n",
    "    cv=10,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    ").fit(prep_x_train, y_train)\n",
    "print(\"best score:\", rf_gs.best_score_)\n",
    "print(\"best parameters:\", rf_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "xgb_gs = GridSearchCV(\n",
    "    xgb_model,\n",
    "    param_grid={\n",
    "        \"n_estimators\": [450, 500],\n",
    "        \"colsample_bytree\": [0.75, 0.8],\n",
    "        \"max_depth\": [None],\n",
    "        \"reg_alpha\": [1],\n",
    "        \"reg_lambda\": [2, 5, 10],\n",
    "        \"subsample\": [0.55, 0.6],\n",
    "        \"learning_rate\": [0.5],\n",
    "        \"gamma\": [0.5, 1],\n",
    "        \"min_child_weight\": [0.01],\n",
    "        \"sampling_method\": [\"uniform\"],\n",
    "    },\n",
    "    cv=5,\n",
    "    verbose=True,\n",
    "    n_jobs=-1,\n",
    ").fit(prep_x_train, y_train)\n",
    "print(\"best score:\", xgb_gs.best_score_)\n",
    "print(\"best parameters:\", xgb_gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop([\"Actor\", \"Character\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.Director.fillna(\"Other\", inplace=True)\n",
    "test_data.Genre.fillna(\"Other\", inplace=True)\n",
    "test_data.MPAA_Rating.fillna(\"Not Rated\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_features(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = column_transformer.transform(test_data)\n",
    "y_test = test_data[\"Success_Level\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"xgb_gs\": xgb_gs,\n",
    "    \"rf_gs\": rf_gs,\n",
    "    \"svc_gs\": svc_gs,\n",
    "    \"knn_gs\": knn_gs,\n",
    "    \"lr_gs\": lr_gs,\n",
    "}\n",
    "\n",
    "\n",
    "def test_model(model_name, model):\n",
    "    print(model_name, model.score(x_test, y_test), end=ENDDEL)\n",
    "\n",
    "\n",
    "for k, v in models.items():\n",
    "    test_model(k, v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
